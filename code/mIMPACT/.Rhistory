getwd()
relative_path <- file.path("..", ".RData")
relative_path <- file.path("..", ".RData")
s <- 1
filename = paste0("../", my_dict[[s]], ".RData")
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
filename = paste0("../", my_dict[[s]], ".RData")
load(filename)
filename = paste0("../../data/multisample data/processed", my_dict[[s]], ".RData")
load(filename)
filename
getwd()
filename = paste0("../../data/multisample data/processed/", my_dict[[s]], ".RData")
load(filename)
filename_2 = paste0("../../data/each_sample/", my_dict[[s]], "/", my_dict[[s]], "_estimated_domain.csv")
spatial_domain_reorder <- read.csv(filename_2)[[1]]
spatial_domain_reorder <- read.csv(filename_2)
directory_path <- "../../fig_result/"
if (!dir.exists(directory_path)) {
dir.create(directory_path)
}
filename = paste0("../../data/multisample data/processed/", my_dict[[s]], ".RData")
load(filename)
spots <- spot_xy
filename = paste0(directory_path, my_dict[[s]],  ".png")
g <- ggplot(df, aes(x = x, y = y, color = domain)) +
geom_point(size = 3) + scale_color_manual(values=c('1' = "#7DFFFF", '2' = "#FFFF00", '3' = "darkorange", '4' = '#00FF00', '5' = 'red2' , '6' = '#0000FF'))+
coord_cartesian(xlim = c(0, 9000), ylim = c(0, 8000))+
theme(panel.background = element_blank())
library(mclust)
library(ggplot2)
filename = paste0(directory_path, my_dict[[s]],  ".png")
g <- ggplot(df, aes(x = x, y = y, color = domain)) +
geom_point(size = 3) + scale_color_manual(values=c('1' = "#7DFFFF", '2' = "#FFFF00", '3' = "darkorange", '4' = '#00FF00', '5' = 'red2' , '6' = '#0000FF'))+
coord_cartesian(xlim = c(0, 9000), ylim = c(0, 8000))+
theme(panel.background = element_blank())
ggsave(filename = filename, plot = g, width = 6, height = 4, dpi = 300)
# spatial_domain_reorder <- switch_color(real_region = real_region, estimated_region = spatial_domain_refined, K = 6)
df <- data.frame(x = spots[,1], y = spots[,2], domain = as.factor(spatial_domain_reorder))
x_trans <- min(df$x)
y_trans <- min(df$y)
df$x <- df$x - x_trans
df$y <- df$y - y_trans
directory_path <- "../../fig_result/"
if (!dir.exists(directory_path)) {
dir.create(directory_path)
}
filename = paste0(directory_path, my_dict[[s]],  ".png")
g <- ggplot(df, aes(x = x, y = y, color = domain)) +
geom_point(size = 3) + scale_color_manual(values=c('1' = "#7DFFFF", '2' = "#FFFF00", '3' = "darkorange", '4' = '#00FF00', '5' = 'red2' , '6' = '#0000FF'))+
coord_cartesian(xlim = c(0, 9000), ylim = c(0, 8000))+
theme(panel.background = element_blank())
ggsave(filename = filename, plot = g, width = 6, height = 4, dpi = 300)
for (s in 1:6){
filename = paste0("../../data/multisample data/processed/", my_dict[[s]], ".RData")
load(filename)
spots <- spot_xy
filename_2 = paste0("../../data/each_sample/", my_dict[[s]], "/", my_dict[[s]], "_estimated_domain.csv")
spatial_domain_reorder <- read.csv(filename_2)[[1]]
# spatial_domain_reorder <- switch_color(real_region = real_region, estimated_region = spatial_domain_refined, K = 6)
df <- data.frame(x = spots[,1], y = spots[,2], domain = as.factor(spatial_domain_reorder))
x_trans <- min(df$x)
y_trans <- min(df$y)
df$x <- df$x - x_trans
df$y <- df$y - y_trans
directory_path <- "../../fig_result/"
if (!dir.exists(directory_path)) {
dir.create(directory_path)
}
filename = paste0(directory_path, my_dict[[s]],  ".png")
g <- ggplot(df, aes(x = x, y = y, color = domain)) +
geom_point(size = 3) + scale_color_manual(values=c('1' = "#7DFFFF", '2' = "#FFFF00", '3' = "darkorange", '4' = '#00FF00', '5' = 'red2' , '6' = '#0000FF'))+
coord_cartesian(xlim = c(0, 9000), ylim = c(0, 8000))+
theme(panel.background = element_blank())
ggsave(filename = filename, plot = g, width = 6, height = 4, dpi = 300)
}
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
library(readr)
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = 1)
## Binary factorization function:
# If method = 1, set 4 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
binary_label <- function(arr, method = 1, red_val = 5, orange_val = 3){
arr <- as.matrix(arr)
# arr <- real_domain
if (method == 1){
ind <- which(arr %in% c(red_val, orange_val))
arr[ind] <- 1
arr[-ind] <- 0
}else if (method == 2){
ind <- which(arr == red_val)
arr[ind] <- 1
arr[-ind] <- 0
}else{
stop('Parameter lattice: Please enter a correct value.')
}
return(arr)
}
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metrix_score) <- c('AUC', 'F1', 'Accuracy')
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
library(readr)
library(pROC)
library(caret)
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = 1)
estimated_binary <- binary_label(estimated_domain, method = 1, red_val = 5, orange_val = 3)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
######## only calculate red region ########
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
s <- 5
folder_name <- paste0("/Users/yanghongguo/Desktop/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_iIMPACT_domain.csv"))))
real_binary <- binary_label(real_domain, method = 2)
estimated_binary <- binary_label(estimated_domain, method = 2, red_val = 5)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
library(pROC)
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
print(auc_value)
# F1 score
library(caret)
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
f1_score <- cm$byClass['F1']
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1, red_val = 5, orange_val = 3){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method, red_val = red_val, orange_val = orange_val)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
s
s<-1
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
s <- 1
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
real_binary <- binary_label(real_domain, method = 1)
estimated_binary <- binary_label(estimated_domain, method = 1, red_val = 5, orange_val = 3)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
folder_name <- paste0("/Users/yanghongguo/Desktop/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_iIMPACT_domain.csv"))))
real_binary <- binary_label(real_domain, method = 2)
estimated_binary <- binary_label(estimated_domain, method = 2, red_val = 5)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
library(pROC)
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
print(auc_value)
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1, red_val = 5, orange_val = 3){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
s <- 1
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method, red_val = red_val, orange_val = orange_val)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, 1] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
## Get AUC, F1 score, Accuracy of the result
# If method = 1, set 3 and 5 to 1, the others to 0;
# if method = 2, set 5 to 1, the others to 0
get_new_metric <- function(method = 1, red_val = 5, orange_val = 3){
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
metric_score <- matrix(NA, nrow = 6, ncol = 3)
colnames(metric_score) <- c('AUC', 'F1', 'Accuracy')
s <- 1
for (s in 1:6){
suppressMessages({
folder_name <- paste0("../../data/each_sample/", my_dict[[s]])
real_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_real_domain.csv"))))
estimated_domain <- as.numeric(as.matrix(read_csv(paste0(folder_name, "/", my_dict[[s]], "_estimated_domain.csv"))))
})
real_binary <- binary_label(real_domain, method = method)
estimated_binary <- binary_label(estimated_domain, method = method, red_val = red_val, orange_val = orange_val)
del_ind <- which(real_domain == 7)
if (length(del_ind) != 0){
real_binary <- real_binary[-del_ind]
estimated_binary <- estimated_binary[-del_ind]
}
# AUC
roc_obj <- roc(response = real_binary, predictor = estimated_binary)
auc_value <- auc(roc_obj)
# F1 score
cm <- confusionMatrix(as.factor(estimated_binary), as.factor(real_binary), mode = 'everything', positive = "1")
precision <- cm$byClass['Pos Pred Value']
recall <- cm$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
# Accuracy
accuracy <- cm$overall['Accuracy']
metric_score[s, ] <- c(auc_value, f1_score, accuracy)
}
return (metric_score)
}
######## only calculate cancer (region with label 3 and 5) ########
metric <- get_new_metric(method = 1)
View(metric)
######## only calculate invasive cancer (region with 5) ########
metric <- get_new_metric(method = 2)
View(metric)
getwd()
my_dict <- list("A1", "B1", "C1", "D1", "G1", "H1")
gene_names <- NULL
for (s in 1:6){
filename = paste0("../../data/multisample data/processed", my_dict[[s]], ".RData")
load(filename)
count <- spot_count[, -1]
gene_names[[s]] <- colnames(count)
}
for (s in 1:6){
filename = paste0("../../data/multisample data/processed/", my_dict[[s]], ".RData")
load(filename)
count <- spot_count[, -1]
gene_names[[s]] <- colnames(count)
}
Rcpp::sourceCpp("bulk_decov.cpp")
